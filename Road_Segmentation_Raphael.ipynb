{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import math \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "from   tensorflow.keras import backend as Ks\n",
    "import theano\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 100 \n",
    "image_dim  = 400\n",
    "\n",
    "working_type = tf.float16\n",
    "image_type   = np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I. Build Training Set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_float_to_uint8(img):\n",
    "    rimg = img - np.min(img)\n",
    "    rimg = (rimg / np.max(rimg) * 255).round().astype(np.uint8)\n",
    "    return rimg\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "def build_training(include_ground_truth = False):\n",
    "    \n",
    "    def concatenate_images(img, gt_img):\n",
    "        nChannels = len(gt_img.shape)\n",
    "        w = gt_img.shape[0]\n",
    "        h = gt_img.shape[1]\n",
    "        if nChannels == 3:\n",
    "            cimg = np.concatenate((img, gt_img), axis=1)\n",
    "        else:\n",
    "            gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "            gt_img8 = img_float_to_uint8(gt_img)          \n",
    "            gt_img_3c[:,:,0] = gt_img8\n",
    "            gt_img_3c[:,:,1] = gt_img8\n",
    "            gt_img_3c[:,:,2] = gt_img8\n",
    "            img8 = img_float_to_uint8(img)\n",
    "            cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "        return cimg\n",
    "\n",
    "    root_dir = \"training/\"\n",
    "    image_dir = root_dir + \"images/\"\n",
    "    files = os.listdir(image_dir)\n",
    "\n",
    "    n = len(files) \n",
    "    imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "    \n",
    "\n",
    "    gt_dir = root_dir + \"groundtruth/\"\n",
    "    gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "    \n",
    "    return  np.array(imgs,dtype = np.float16)\n",
    "    #return tf.data.Dataset.from_tensor_slices((imgs, gt_imgs))\n",
    "    #return np.array([concatenate_images(imgs[0], gt_imgs[0]) for i in range(n)],dtype=np.uint8)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 100, 3)\n",
      "(320000, 15, 15, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (320000,15,15,3) into shape (32,15,15,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5675b88b0cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1878\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    333\u001b[0m           \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (320000,15,15,3) into shape (32,15,15,3)"
     ]
    }
   ],
   "source": [
    "patch_shape          = (400,400,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "window_size      = 15   # must be odd \n",
    "pool_size        = 4    # must be either 1,2,4,16\n",
    "training_samples = int((image_dim/pool_size)**2*num_images)\n",
    "\n",
    "training                  =  build_training()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rgb_input                 =  ks.layers.Input(shape=patch_shape, dtype='float16', name='rgb_input' )\n",
    "rgb_pooled                =  ks.layers.AveragePooling2D(pool_size=(pool_size, pool_size)       , name='rgb_pooled') (rgb_input)\n",
    "rgb_tiled                 =  ks.layers.Lambda(\\\n",
    "                                lambda img : tf.reshape(tf.image.extract_image_patches(img,\n",
    "                                             [1,window_size,window_size,1],[1,1,1,1],[1,1,1,1],\n",
    "                                             \"SAME\"),[-1,int(image_dim/pool_size),int(image_dim/pool_size),window_size,window_size,3]),\n",
    "                                              name='rgb_tiled')(rgb_pooled)\n",
    "rgb_resized               =  ks.layers.Lambda(\\\n",
    "                                lambda img: tf.reshape(img,[32*100*100,window_size,window_size,3]))(rgb_tiled)\n",
    "    \n",
    "model                     =  ks.Model(inputs=[rgb_input], outputs=[rgb_resized])\n",
    "\n",
    "\n",
    "print(rgb_pooled.shape)\n",
    "print(rgb_resized.shape)\n",
    "\n",
    "\n",
    "\n",
    "features = model.predict(training)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(features[1].astype(np.float32))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training[1].astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II.Setup Convolution **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_tensor): \n",
    "    shape    = tf.shape(input_tensor)\n",
    "    shape    = [shape[0],shape[1],shape[2],1]\n",
    "    return tf.reshape(input_tensor/tf.reduce_max(tf.abs(input_tensor)),shape)\n",
    "\n",
    "def greyscale(input_tensor): \n",
    "    return normalize(tf.reduce_mean(input_tensor,axis=3))\n",
    "\n",
    "def blur(input_tensor,blur_width): \n",
    "    \n",
    "    kernel = np.ones([blur_width,blur_width])\n",
    "    with tf.name_scope('convolution'):\n",
    "        conv     = tf.constant(kernel, dtype=working_type, shape=(blur_width, blur_width, 1, 1)) \n",
    "        output   = tf.nn.conv2d(input=input_tensor, filter=conv, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    return normalize(output)\n",
    "\n",
    "def sobel(input_tensor): \n",
    "\n",
    "    kernel_h = np.array([3, 3])\n",
    "    kernel_h = [ [1,2,1], [0,0,0], [-1,-2,-1] ]\n",
    "    kernel_v = np.array([3, 3])\n",
    "    kernel_v = [ [1,0,1], [2,0,-2], [-1,0,-1] ]\n",
    "\n",
    "    with tf.name_scope('convolution'):\n",
    "        conv_w_h = tf.constant(kernel_h, dtype=working_type, shape=(3, 3, 1, 1))\n",
    "        conv_w_v = tf.constant(kernel_v, dtype=working_type, shape=(3, 3, 1, 1))    \n",
    "        output_h = tf.nn.conv2d(input=input_tensor, filter=conv_w_h, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        output_v = tf.nn.conv2d(input=input_tensor, filter=conv_w_v, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        output   = (output_h**2 + output_v**2)**0.5        \n",
    "    \n",
    "    return normalize(output) \n",
    "\n",
    "\n",
    "def RGB(input_tensor, op): \n",
    "      \n",
    "    shape    = tf.shape(input_tensor)\n",
    "    shape    = [shape[0],shape[1],shape[2],1]\n",
    "    \n",
    "    R     = tf.cast(tf.reshape(input_tensor[:,:,:,0],shape),working_type)\n",
    "    G     = tf.cast(tf.reshape(input_tensor[:,:,:,1],shape),working_type)\n",
    "    B     = tf.cast(tf.reshape(input_tensor[:,:,:,2],shape),working_type) \n",
    "    \n",
    "    return ((op(R)**2+op(G)**2+op(B)**2)**0.5)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "input_placeholder = tf.placeholder( dtype=working_type, shape=(num_images, image_dim, image_dim, 3))\n",
    "training    = build_training()\n",
    "output_1    = RGB(input_placeholder,lambda x:sobel(blur(x,4)))\n",
    "output_2    = sobel(blur(greyscale(input_placeholder),4))\n",
    "\n",
    "result_1    = tf.Session().run(output_1, feed_dict={input_placeholder: training})\n",
    "result_2    = tf.Session().run(output_2, feed_dict={input_placeholder: training})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# https://medium.com/@tempflip/lane-detection-with-numpy-2-hough-transform-f4c017f4da39\n",
    "##\n",
    "\n",
    "def build_hough_lines(input_tensor,num_thetas,num_diams): \n",
    "    \n",
    "    hough       = np.zeros((num_thetas,num_diams))\n",
    "    theta_space = np.linspace(0, 2*math.pi, num_thetas)\n",
    "    rad_space   = np.linspace(0,(img_shape/2)*(2**0.5),num_diams)\n",
    "    \n",
    "    for i,theta in enumerate(theta_space):\n",
    "        for j, rad in enumerate(rad_space): \n",
    "            hough[i,j] = \n",
    "            \n",
    "            x1 = image_dim/2 + diam*math.cos(theta)\n",
    "            y1 = image_dim/2 + diam*math.sin(theta)\n",
    "            \n",
    "            x2 = 0 \n",
    "            x2 = im\n",
    "            \n",
    "            \n",
    "            dx = x2 - x1\n",
    "            dy = y2 - y1\n",
    "for x from x1 to x2 {\n",
    "  y = y1 + dy * (x - x1) / dx\n",
    "  plot(x, y)\n",
    "}\n",
    "    \n",
    "def build_hough_space_fom_image(img, shape = (100, 300), val = 1):\n",
    "    hough_space = np.zeros(shape)\n",
    "    for i, row in enumerate(img):\n",
    "        for j, pixel in enumerate(row):   \n",
    "            if pixel != val : continue\n",
    "            hough_space = add_to_hough_space_polar((i,j), hough_space)\n",
    "    return hough_space\n",
    "\n",
    "def add_to_hough_space_polar(p, feature_space):\n",
    "    \n",
    "    d_max = len(feature_space[0]) / 2\n",
    "    for i in range(len(space)):\n",
    "        theta = space[i]\n",
    "        d = int(p[0] * math.sin(theta) + p[1] * math.cos(theta)) + d_max\n",
    "        if (d >= d_max * 2) : continue\n",
    "        feature_space[i, d] += 1\n",
    "    return feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = build_hough_space_fom_image(result_1[1].reshape(400,400), shape = (400, 400), val = 0)\n",
    "plt.imshow(res.astype(np.float32),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = build_training()\n",
    "\n",
    "def fully_connected_layers(num_layers):\n",
    "    \n",
    "    connected_layers =[{'weights':tf.Variable(tf.random_normal([shape])),\n",
    "                       'biases' :tf.Variable(tf.random_normal( shape )),\n",
    "                        ''} for i in range(num_layers)]\n",
    "    \n",
    "    for i in range(num_layers): \n",
    "        connected_layer_ = \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf.to_float(output_2[2]),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(training[2, :, :,:].astype(np.float32),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(output_1[2, :, :,:].astype(np.float32),cmap='hot')\n",
    "plt.imshow(result_1[2].astype(np.float32).reshape(400,400),cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
